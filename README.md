# AIYolo - 基于YOLOv8目标检测与跟踪系统

这是一个基于YOLOv8目标检测与跟踪系统，可以实现：
- 人员检测与跟踪
- 物品（如书包）检测与跟踪
- 人员携带物品识别
- 安全区域入侵检测
- 目标轨迹记录与显示

## 环境要求

- Python 3.13
- OpenCV
- PyTorch
- Ultralytics (YOLO11)

## 安装步骤

1. 克隆仓库：
```bash
git clone https://github.com/yourusername/aiyolo.git
cd aiyolo
```

2. 安装依赖：
```bash
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
```

3. 下载YOLO11模型：
```bash
# 模型会自动下载，或手动下载后放入项目目录
```

## 使用方法

运行主程序：
```bash
.venv\Scripts\activate
python aiyolo/main.py
```

- 程序启动后http://localhost:5000/video_feed 可以看到视频流
- 红色矩形框表示安全区域
- 绿色框表示检测到的目标
- 绿色线条表示目标运动轨迹


表现层：main.py 负责视频流处理和可视化
业务层：tracker.py 实现核心跟踪逻辑
工具层：utils.py 提供通用功能支持
模型层：yolo_infer.py 封装深度学习模型， YOLO检测器接口

## 功能说明

1. 目标检测：使用YOLOv8进行实时目标检测
2. 安全区域：检测目标是否进入预设的安全区域
3. 告警功能：当目标进入安全区域时发出警告

## 注意事项

- 确保摄像头可用
- 首次运行时会自动下载YOLOv8模型
- 可以根据需要调整安全区域的大小和位置 



界面上的几个框和线条：
红色框：表示安全区域，当目标进入这个区域时会触发警告
绿色框：表示当前检测到的目标位置
黄色框：表示预测的未来位置（5秒后可能到达的位置）
让我们修改代码，先注释掉轨迹线的显示：


使用一个基于质心的简单跟踪方法，不使用 OpenCV 的跟踪器。这个方法的优点是：
不依赖 OpenCV 的跟踪器 API
实现简单，容易理解和维护
性能足够好，适合大多数场景

这个新的跟踪器实现：
使用质心距离来匹配目标
不依赖 OpenCV 的跟踪器 API
保持了原有的功能（轨迹记录、速度计算、位置预测等）


红色框（安全区域）：
位于画面中心区域
当目标进入这个区域时会触发警告
使用 cv2.rectangle 绘制，颜色为 (0, 0, 255)（BGR格式的红色）
绿色框（当前目标）：
表示当前检测到的目标位置
包含目标类别和ID信息
使用 draw_bbox 函数绘制，颜色为绿色
黄色框（预测位置）：
表示目标5秒后可能到达的位置
基于目标当前速度和方向计算
使用 cv2.rectangle 绘制，颜色为 (0, 255, 255)（BGR格式的黄色）

如果你觉得预测框（黄色框）的效果也不够好，我们也可以把它注释掉。